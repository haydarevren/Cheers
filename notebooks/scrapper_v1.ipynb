{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Beer Engine\r\n",
    "\r\n",
    "Notebook 1: Webscraper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import csv\r\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 1 - Get links for each beer\n",
    "\n",
    "1. Compile dictionaries of beer categories/subcategories\n",
    "2. Create dictionary of beer links per subcategory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_list(link):\r\n",
    "    \r\n",
    "    \"\"\" \r\n",
    "    This function returns a list of websites for each beer in the input, 'link', where \r\n",
    "    'link' is the website for the 'top 250' beer list webpage. \r\n",
    "    \r\n",
    "    INPUT: str (from the above dictionaries - 'dict[key]')\r\n",
    "    OUTPUT: list\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    response = requests.get(link)\r\n",
    "    page = response.text\r\n",
    "    soup = BeautifulSoup(page, \"lxml\")\r\n",
    "    table = soup.findAll(\"table\")\r\n",
    "    data_rows = table[0].findAll('tr')[2:]\r\n",
    "    # Retrive segment of url link for each specific beer in the \"top\" list\r\n",
    "    html_sublist=[]\r\n",
    "    for i in range(len(data_rows)):\r\n",
    "        link = data_rows[i].find('a')['href']\r\n",
    "        html_sublist.append(link)\r\n",
    "    # concatenate first part and second part of url to get to reviews page of each beer\r\n",
    "    fulllist = ['https://www.beeradvocate.com' + html_sublist[i] +'?view=beer&sort=&start=' for i in range(len(html_sublist))]        \r\n",
    "    return fulllist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def compile_list(dic):\r\n",
    "    \"\"\"\r\n",
    "    compiles list of links from dictionary of subcategory of beer type\r\n",
    "    Input: dictionary\r\n",
    "    Output: dictionary\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    beers_dict = dict()\r\n",
    "    temp_list = list(dic.keys())\r\n",
    "    ts = time.time()\r\n",
    "    \r\n",
    "    for i in range(len(dic)):\r\n",
    "        beers_dict[temp_list[i]] = get_list(dic[temp_list[i]]) # call get_list function\r\n",
    "    \r\n",
    "    # pickle dictionary\r\n",
    "    # note: timestamp used for name of each pickled dict\r\n",
    "    filename = str(ts)+'_dict.pkl'\r\n",
    "    with open(filename, 'wb') as f:\r\n",
    "        pickle.dump(beers_dict, f)\r\n",
    "        f.close()\r\n",
    "        \r\n",
    "    # return object\r\n",
    "    return beers_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 2 - Scrape every beer link\r\n",
    "\r\n",
    "After getting the link for each unqiue beer, the following section will scrape the following information for each beer:\r\n",
    "\r\n",
    "beer name  \r\n",
    "brewery name  \r\n",
    "beer subcategory  \r\n",
    "overall rating  \r\n",
    "number of ratings  \r\n",
    "number of reviews  \r\n",
    "alcohol percentage (ABV)\r\n",
    "reviews"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def access_url(beer_type):\r\n",
    "    \"\"\" access url and retrieve bs4 lxml object\"\"\"\r\n",
    "    new_url = beer_type\r\n",
    "    new_response = requests.get(new_url)\r\n",
    "    new_page = new_response.text\r\n",
    "    new_soup = BeautifulSoup(new_page, \"lxml\")\r\n",
    "    return new_soup\r\n",
    "\r\n",
    "\r\n",
    "def get_beer_info(new_soup):\r\n",
    "    \"\"\" retrieve name of beer, name of brewery\"\"\"  \r\n",
    "    name = new_soup.findAll(class_='titleBar')\r\n",
    "    name = name[0].text.replace('\\n','').split('|')\r\n",
    "    beer_name = name[0]\r\n",
    "    brewery_name = name[1]\r\n",
    "    return beer_name, brewery_name\r\n",
    "\r\n",
    "\r\n",
    "def get_rating(new_soup):\r\n",
    "    \"\"\" retrieve rating of beer\"\"\"   \r\n",
    "    ba_score = new_soup.findAll(class_='ba-ravg')\r\n",
    "    rating = ba_score[0].text\r\n",
    "    return rating\r\n",
    "\r\n",
    "\r\n",
    "def get_num_rating(new_soup):\r\n",
    "    \"\"\"retrieve no. of ratings\"\"\"   \r\n",
    "    num_ratings = new_soup.findAll(class_='ba-ratings')\r\n",
    "    num_ratings = num_ratings[0].text\r\n",
    "    return num_ratings\r\n",
    "\r\n",
    "\r\n",
    "def get_num_reviews(new_soup):\r\n",
    "    \"\"\" retrieve no. of reviews \"\"\"   \r\n",
    "    num_reviews = new_soup.findAll(class_='ba-reviews')\r\n",
    "    num_reviews = num_reviews[0].text\r\n",
    "    return num_reviews \r\n",
    "\r\n",
    "\r\n",
    "def get_abv(new_soup):\r\n",
    "    \"\"\" retrieve abv\"\"\"\r\n",
    "    letters = 'abcdefghijklmnopqrstuwvxyz'\r\n",
    "    abv_info = new_soup.findAll('div', {'id':'info_box'})\r\n",
    "    for item in abv_info:\r\n",
    "        ary = item.text.split('\\n')\r\n",
    "        for i in ary:\r\n",
    "            if 'Alcohol by volume' in i:\r\n",
    "                abv_string = i\r\n",
    "                abv_ = abv_string.split(' ')[-1]\r\n",
    "                chars = list(abv_)\r\n",
    "                if chars[-2] not in letters:\r\n",
    "                    abv = round(float(abv_.strip('%')),2)\r\n",
    "                    return abv\r\n",
    "                else:\r\n",
    "                    return 'N/A'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_info(beer_dict):\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    function to scrape key info and append to csv\r\n",
    "    \"\"\" \r\n",
    "    compiled_list =[]\r\n",
    "    \r\n",
    "    dict_keys = list(beer_dict.keys())\r\n",
    "    for i in dict_keys:\r\n",
    "        list_ = beer_dict[i]  # list of beers from dict_key \"i\"\r\n",
    "        new_list = [x + '0' for x in list_]  # add 0 to end of website link to get to first page\r\n",
    "        # loop through each link in new_list\r\n",
    "        for link in new_list:\r\n",
    "            url = access_url(link)\r\n",
    "            beer_name, brewery_name = get_beer_info(url)\r\n",
    "            rating = get_rating(url)\r\n",
    "            num_ratings = get_num_rating(url)\r\n",
    "            num_reviews = get_num_reviews(url)\r\n",
    "            alc = get_abv(url)\r\n",
    "            # get name of dictionary list to represent which category of beer\r\n",
    "            beer_sub_cat = i \r\n",
    "            beerlist = [beer_sub_cat,beer_name, brewery_name, rating, num_ratings, num_reviews, alc]\r\n",
    "            \r\n",
    "            print(beerlist)\r\n",
    "            compiled_list.append(beerlist)\r\n",
    "            \r\n",
    "            # insert data into mongoDB\r\n",
    "            beer_dict_db = {}\r\n",
    "            beer_dict_db['sub_cat'] = beer_sub_cat\r\n",
    "            beer_dict_db['beer_name'] = beer_name\r\n",
    "            beer_dict_db['brewery_name'] = brewery_name\r\n",
    "            beer_dict_db['rating'] = rating\r\n",
    "            beer_dict_db['num_ratings'] = num_ratings\r\n",
    "            beer_dict_db['num_reviews'] = num_reviews\r\n",
    "            beer_dict_db['alc'] = alc\r\n",
    "            client.beer_db.beer_collection.insert_one(beer_dict_db)\r\n",
    "            print('mongo insert complete')\r\n",
    "            \r\n",
    "    return compiled_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 3 - Scrape User Ratings\n",
    "\n",
    "Scrape all user review(rating) for each unique beer. This is different than Part 2. Part 2 extracts all relevant info on the first page of each unique beer. Part 3 iterates through each page to extract all user - rating pairings. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "user_reviews_assorted = beer_db['user_reviews_assorted'] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_rate_count(new_soup):\r\n",
    "    \"\"\" \r\n",
    "    find number of ratings to determine number of iterations \r\n",
    "    input: bs4 object\r\n",
    "    output: integer\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    rating = new_soup.findAll(class_='ba-ratings')\r\n",
    "    rc = rating[0].text\r\n",
    "    rating_count = int(rc.replace(',',''))\r\n",
    "    # divide rating by 25 and round down to get number of iterations\r\n",
    "    ct = rating_count//25 \r\n",
    "    # return last page (intger)\r\n",
    "    page_end_ = ct*25\r\n",
    "    return page_end_\r\n",
    "\r\n",
    "\r\n",
    "def get_rating_reviewer(soup_):\r\n",
    "    \"\"\"\r\n",
    "    retreive all of the reviewer - rating pairs on each webpage\r\n",
    "    \r\n",
    "    Input: bs4 object \r\n",
    "    Output: list of 25 username, rating tuple pairs\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    info_ = soup_.findAll(class_='BAscore_norm')\r\n",
    "    info_user = soup_.findAll(class_='username')\r\n",
    "    tuple_list = []\r\n",
    "    user_list = []\r\n",
    "    rating_list = []\r\n",
    "    \r\n",
    "    # get list of users\r\n",
    "    for i in range(len(info_user)):\r\n",
    "        if info_user[i].text is not '':\r\n",
    "            user_list.append(info_user[i].text)\r\n",
    "    user_list = user_list[1:]\r\n",
    "    \r\n",
    "    # get list of ratings\r\n",
    "    for i in range(len(info_)):\r\n",
    "        uni_rating = float(info_[i].text)\r\n",
    "        uni_rating2 = format(uni_rating, '.2f')\r\n",
    "        rating_list.append(uni_rating2)\r\n",
    "    \r\n",
    "    # append users and ratings as tuple pair\r\n",
    "    for i in range(len(user_list)):\r\n",
    "        t = user_list[i], rating_list[i]\r\n",
    "        tuple_list.append(t)\r\n",
    "\r\n",
    "    return tuple_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rating_reviewers(beer_dict):\r\n",
    "    '''\r\n",
    "    Get ratings and reviewers\r\n",
    "    \r\n",
    "    '''\r\n",
    "    # initiate master dictionary \r\n",
    "    user_reviews_beer_dict={}\r\n",
    "    beer_tuple_list=[] \r\n",
    "    \r\n",
    "    dict_keys = list(beer_dict.keys())\r\n",
    "\r\n",
    "    for i in dict_keys:\r\n",
    "        list_ = beer_dict[i]  # list of beers from dict_key \"i\"\r\n",
    "        for link in list_:\r\n",
    "            letters = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\r\n",
    "            start = 0\r\n",
    "            page_end = 2 #integer representing the last page, 2 is placeholder  \r\n",
    "            count = 0\r\n",
    "\r\n",
    "            while count <= page_end:\r\n",
    "                if count ==0:\r\n",
    "                    time.sleep(1)\r\n",
    "                    first_page = link+'0'\r\n",
    "                    url = access_url(first_page)\r\n",
    "\r\n",
    "                    # find number of ratings to determine number of iterations (turn this into function)\r\n",
    "                    page_end = find_rate_count(url) \r\n",
    "\r\n",
    "                    # get name of beer\r\n",
    "                    beer_name_, brewery_name = get_beer_info(url)\r\n",
    "\r\n",
    "                    beer_name = beer_name_.replace('.','').replace('$','')\r\n",
    "                    \r\n",
    "                    # get individual rating, get reviewer name\r\n",
    "                    tup = get_rating_reviewer(url)\r\n",
    "                    \r\n",
    "                    # initiate new dict key-value\r\n",
    "                    user_reviews_beer_dict[beer_name]=[]\r\n",
    "                    # append to dict\r\n",
    "                    for item in tup:\r\n",
    "                        user_reviews_beer_dict[beer_name].append(item)                    \r\n",
    "                    count +=25\r\n",
    "\r\n",
    "                else:\r\n",
    "                    other_pages = link + str(count)\r\n",
    "                    url = access_url(other_pages)\r\n",
    "\r\n",
    "                    # get individual rating, get reviewer name\r\n",
    "                    tup = get_rating_reviewer(url)\r\n",
    "                    \r\n",
    "                    # append to dict\r\n",
    "                    for item in tup:\r\n",
    "                        user_reviews_beer_dict[beer_name].append(item)\r\n",
    "                    count +=25\r\n",
    "    \r\n",
    "    \r\n",
    "    # extract data and insert into MongoDB\r\n",
    "    all_reviews = []\r\n",
    "\r\n",
    "    for key in list(user_reviews_beer_dict.keys()):\r\n",
    "        d = {}\r\n",
    "        d['Beer'] = key\r\n",
    "        d['UserReviews'] = user_reviews_beer_dict[key]\r\n",
    "        all_reviews.append(d)\r\n",
    "\r\n",
    "    \r\n",
    "    for item in all_reviews:\r\n",
    "        client.beer_db.user_reviews_assorted.insert_one(item)\r\n",
    "    \r\n",
    "    # return dictionary object\r\n",
    "    return user_reviews_beer_dict\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}